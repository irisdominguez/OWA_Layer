{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy.signal\n",
    "from fastai.vision import *\n",
    "\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_REF = \"t5_reference\"\n",
    "REF_FILE = f\"res/{EXP_REF}.txt\"\n",
    "REF_MATRIX_FOLDER = f\"matrixes/{EXP_REF}\"\n",
    "\n",
    "## Uncomment the experiment to analyze\n",
    "#EXP = \"t5_init\"\n",
    "#EXP = \"t5_feats\"\n",
    "#EXP = \"t5_metrics\"\n",
    "FILE_TO_LOAD = f\"res/{EXP}.txt\"\n",
    "MATRIX_FOLDER = f\"matrixes/{EXP}\"\n",
    "\n",
    "EXP_TAG = EXP[EXP.find('_')+1:]\n",
    "print(f'Experiment type: {EXP_TAG}')\n",
    "\n",
    "pthr = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_config(c):\n",
    "    c = c.rstrip(\"\\n\")\n",
    "    c = re.sub(r'<function (\\w+) at \\w+>', r\"'\\1'\", c)\n",
    "    c = re.sub(r'\"data\": \"[^\"]+\", ', r\"\", c)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_configs = []\n",
    "configs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(REF_FILE, 'r')\n",
    "lines = file.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    c = json.loads(pretty_config(line))\n",
    "    if c['config']['type'] == 'reference': \n",
    "        full_configs.append(c)\n",
    "        configs.append(c['config'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(FILE_TO_LOAD, 'r')\n",
    "lines = file.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    c = json.loads(pretty_config(line))\n",
    "    full_configs.append(c)\n",
    "    configs.append(c['config'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.empty((len(full_configs), \n",
    "                    len(full_configs[0]['results']), \n",
    "                    len(full_configs[0]['results'][0]['accuracy'])))\n",
    "for i, c in enumerate(full_configs):\n",
    "    for j, r in enumerate(c['results']):\n",
    "        results[i, j, :] = np.array(r['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = None\n",
    "pvalues = []\n",
    "\n",
    "for i in range(len(configs)):\n",
    "    c = configs[i]\n",
    "    r = results[i, :, -1]\n",
    "    if ref is None and c['type'] == 'reference':\n",
    "        ref = r \n",
    "    if ref is not None:\n",
    "        pvalue = scipy.stats.mannwhitneyu(r, ref, alternative='two-sided').pvalue\n",
    "    else:\n",
    "        pvalue = 1.0\n",
    "    pvalues.append(pvalue)\n",
    "    print('-----------')\n",
    "    print('Config:', c)\n",
    "    print(f'Mean: {np.mean(r)*100:.2f}  |  Median: {np.median(r)*100:.2f}')\n",
    "    print(f'P-value: [{pvalue < pthr}] {pvalue}')\n",
    "    totalTime = 0\n",
    "    for j, r in enumerate(full_configs[i]['results']):\n",
    "        totalTime += r['time']\n",
    "    print(f'Time: {int(totalTime / 60)} mins ({round(totalTime / 3600, 1)} hours)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertMetric(order):\n",
    "    order = order.replace('\\'', '')\n",
    "    order = order.replace('_image_batch', '')\n",
    "    if order == 'total_variation':\n",
    "        return r'$\\text{TV}$'\n",
    "    elif order == 'activation_sum':\n",
    "        return r'$\\text{Sum}$'\n",
    "    elif order == 'entropy':\n",
    "        return r'$H$'\n",
    "    elif order == 'entropy_shannon_1diff':\n",
    "        return r'$H_{sv}$'\n",
    "    elif order == 'max_activation':\n",
    "        return r'$\\text{Max}$'\n",
    "    elif order == 'median_activation':\n",
    "        return r'$\\text{Median}$'\n",
    "    return order\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsForTable = {}\n",
    "\n",
    "for i in range(len(configs)):\n",
    "    c = configs[i]\n",
    "    r = results[i, :, -1]\n",
    "    if ref is None and c['type'] == 'reference':\n",
    "        ref = r \n",
    "        pvalue = 1.0\n",
    "    else:\n",
    "        pvalue = scipy.stats.mannwhitneyu(r, ref, alternative='two-sided').pvalue\n",
    "    \n",
    "    std = np.std(r)\n",
    "    ss = '*' if pvalue <= 0.05 else ''\n",
    "    \n",
    "    if i == 0:\n",
    "        pvalue = ''\n",
    "    elif pvalue < .001:\n",
    "        pvalue = f'$<.001$*'\n",
    "    elif pvalue < .05:\n",
    "        pvalue = f'${f\"{pvalue:0.3f}\"[1:]}$*'\n",
    "    else:\n",
    "        pvalue = f'${f\"{pvalue:0.3f}\"[1:]}$'\n",
    "\n",
    "    if EXP_TAG == \"init\":\n",
    "        init = c['init_denominator'] if 'init_denominator' in c else 'Reference'\n",
    "        resultsForTable[i] = {'Init $\\\\alpha$': init, 'Top 5 acc.': f'${np.mean(r) * 100:.2f}\\pm{std * 100:.1f}$', 'p-value': pvalue}\n",
    "    \n",
    "    elif EXP_TAG == \"feats\":\n",
    "        feats = c['pos']['3'] if 'pos' in c else 'Reference'\n",
    "        resultsForTable[i] = {'C_{f}': feats, 'Top 5 acc.': f'${np.mean(r) * 100:.2f}\\pm{std * 100:.1f}$', 'p-value': pvalue}\n",
    "    \n",
    "    elif EXP_TAG == \"metrics\":\n",
    "        order = 'Reference'\n",
    "        if 'order' in c:\n",
    "            order = convertMetric(c['order'])\n",
    "        resultsForTable[i] = {'Metric': order, 'Top 5 acc.': f'${np.mean(r) * 100:.2f}\\pm{std * 100:.1f}$', 'p-value': pvalue}\n",
    "\n",
    "df = pd.DataFrame.from_dict(resultsForTable, orient='index')\n",
    "if EXP_TAG == \"metrics\":\n",
    "    df = df.sort_values(by='Top 5 acc.')\n",
    "print(df.to_latex(index=False, escape=False, column_format='rrr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMI = None\n",
    "LIMS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.sort(results, axis=1)[:, LIMI:LIMS, -1].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette=[]\n",
    "for i, c in enumerate(configs):\n",
    "    if c['type'] == 'reference':\n",
    "        palette.append((1, 1, 1))\n",
    "    else:\n",
    "        p = int((1 - pvalues[i]) * 100)\n",
    "        p = np.clip(p, 0, 99)\n",
    "        palette.append(sns.color_palette('plasma', n_colors=100)[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_errors(ref, r, x):\n",
    "    y = np.mean(r, axis=1)\n",
    "    std = np.std(r, axis=1)\n",
    "    \n",
    "    ref_y = np.repeat(np.mean(ref, axis=0), r.shape[0], 0)\n",
    "    ref_std = np.repeat(np.std(ref, axis=0), r.shape[0], 0)\n",
    "    \n",
    "    plt.xscale('log')\n",
    "    \n",
    "    plt.plot(x, ref_y, color='#4FCC1B')\n",
    "    plt.fill_between(x, ref_y-ref_std, ref_y+ref_std,\n",
    "        alpha=0.5, edgecolor='#4FCC1B', facecolor='#98FF48')\n",
    "    \n",
    "    plt.plot(x, y, color='#CC4F1B')\n",
    "    plt.fill_between(x, y-std, y+std,\n",
    "        alpha=0.5, edgecolor='#CC4F1B', facecolor='#FF9848')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orness(m):\n",
    "    if type(m) is not np.ndarray:\n",
    "        m = m.numpy()\n",
    "    mask = np.repeat(((m.shape[1] - np.arange(m.shape[1])) / m.shape[1]).reshape(1, -1), m.shape[0], axis=0)\n",
    "    orness = np.sum(np.multiply(m, mask), axis=1)\n",
    "    return orness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispersion(m):\n",
    "    if type(m) is not np.ndarray:\n",
    "        m = m.numpy()\n",
    "    m = np.clip(m, 0.000001, 1)\n",
    "    dispersion = -np.sum(np.multiply(m, np.log(m)), axis=1)\n",
    "    return dispersion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([10, 20 , 30])\n",
    "plt.show()\n",
    "\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    \"pgf.preamble\": \"\\n\".join([\n",
    "         \"\\\\usepackage{amsmath}\"\n",
    "    ]),\n",
    "    'pgf.rcfonts': False,\n",
    "    'figure.dpi': 300,\n",
    "    'legend.fontsize': 'small',\n",
    "    'axes.labelsize': 'small',\n",
    "    'axes.titlesize': 'small',\n",
    "    'xtick.labelsize': 'small',\n",
    "    'ytick.labelsize': 'small',\n",
    "    'legend.markerscale': 0.6,\n",
    "    'legend.handlelength': 1.0\n",
    "})\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.plot([10, 20 , 30])\n",
    "plt.show()\n",
    "\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXP_TAG == 'init':\n",
    "    def get_matrixes(config):\n",
    "        if 'constrainmode' in config['config']:\n",
    "            constrain = WeightConstraint(config['config']['constrainmode']).apply\n",
    "        else:\n",
    "            constrain = WeightConstraint('full_owa').apply\n",
    "        mats = []\n",
    "        for it in config['results']:\n",
    "            itid= it['id']\n",
    "            for file in os.listdir(MATRIX_FOLDER):\n",
    "                if file.startswith(itid):\n",
    "                    path = os.path.join(MATRIX_FOLDER, file)\n",
    "                    raw_matrix = torch.Tensor(np.load(path, allow_pickle=True))\n",
    "                    matrix = constrain(raw_matrix)\n",
    "                    mats += [matrix[np.argsort(orness(matrix)),:]]\n",
    "        return mats\n",
    "\n",
    "    mats = []\n",
    "    for f in full_configs:\n",
    "        newmats = get_matrixes(f)\n",
    "        if len(newmats) > 0:\n",
    "            mats += [np.stack(newmats, axis=0)]\n",
    "\n",
    "    mats = np.stack(mats, axis=0)\n",
    "    \n",
    "    filt_configs = configs[1:]\n",
    "\n",
    "    meanmats = np.mean(mats, axis=1)\n",
    "    \n",
    "    assert len(filt_configs) == meanmats.shape[0]\n",
    "    \n",
    "    ornessess = np.empty((len(filt_configs), meanmats.shape[1]))\n",
    "    denominators = []\n",
    "    for i in range(meanmats.shape[0]):\n",
    "        denominators += [filt_configs[i]['init_denominator']]\n",
    "        ornessess[i, :] = orness(meanmats[i,...])\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_prop_cycle(plt.cycler('color', plt.cm.jet(np.linspace(0, 1, len(filt_configs)))))\n",
    "    ax.plot(ornessess.T)\n",
    "    ax.legend(denominators, ncol=3)\n",
    "    ax.set_xlabel('Feature')\n",
    "    ax.set_ylabel('Orness')\n",
    "    \n",
    "    fig.set_size_inches(w=3.5, h=2.5)\n",
    "    plt.tight_layout()\n",
    "    fig.show()\n",
    "    plt.savefig(f'latex_figures/exp_init_orness.pgf')\n",
    "    \n",
    "    dispersions = np.empty((len(filt_configs), meanmats.shape[1]))\n",
    "    denominators = []\n",
    "    for i in range(meanmats.shape[0]):\n",
    "        denominators += [filt_configs[i]['init_denominator']]\n",
    "        dispersions[i, :] = dispersion(meanmats[i,...])\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_prop_cycle(plt.cycler('color', plt.cm.jet(np.linspace(0, 1, len(filt_configs)))))\n",
    "    ax.plot(dispersions.T)\n",
    "    ax.legend(denominators, ncol=3)\n",
    "    ax.set_xlabel('Feature')\n",
    "    ax.set_ylabel('Dispersion')\n",
    "    \n",
    "    fig.set_size_inches(w=3.5, h=2.5)\n",
    "    plt.tight_layout()\n",
    "    fig.show()\n",
    "    plt.savefig(f'latex_figures/exp_init_dispersion.pgf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXP_TAG == 'feats':\n",
    "    results_filt = np.concatenate((results[:1, ...], results[3:, ...]), axis=0)\n",
    "    results_filt = results\n",
    "    \n",
    "    palette=[(1, 1, 1)]\n",
    "    for i in range(results_filt.shape[0] - 1):\n",
    "        palette.append(sns.cubehelix_palette(rot=-.5, start=.5, dark=0.5, n_colors=results_filt.shape[0] - 1)[i])\n",
    "\n",
    "    df = pd.DataFrame(np.sort(results_filt, axis=1)[:, :, -1].T, \n",
    "                      columns=['Ref',1,2,4,8,16,32,64,128,256,512][:results_filt.shape[0]])\n",
    "    df = df * 100\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.violinplot(data=df, orient='h', palette=palette, linewidth=0.8)\n",
    "    ax.set_xlabel('Top-5 Accuracy')\n",
    "    plt.show()\n",
    "    \n",
    "    fig.set_size_inches(w=3.5, h=2.6)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'latex_figures/exp_feats_accuracies.pgf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXP_TAG == 'feats':\n",
    "    def get_matrixes(config):\n",
    "        if 'constrainmode' in config['config']:\n",
    "            constrain = WeightConstraint(config['config']['constrainmode']).apply\n",
    "        else:\n",
    "            constrain = WeightConstraint('full_owa').apply\n",
    "        mats = []\n",
    "        for it in config['results']:\n",
    "            itid= it['id']\n",
    "            for file in os.listdir(MATRIX_FOLDER):\n",
    "                if file.startswith(itid):\n",
    "                    path = os.path.join(MATRIX_FOLDER, file)\n",
    "                    raw_matrix = torch.Tensor(np.load(path, allow_pickle=True))\n",
    "                    matrix = constrain(raw_matrix)\n",
    "                    mats += [matrix[np.argsort(orness(matrix)),:]]\n",
    "            for file in os.listdir(REF_MATRIX_FOLDER):\n",
    "                if file.startswith(itid):\n",
    "                    path = os.path.join(REF_MATRIX_FOLDER, file)\n",
    "                    raw_matrix = torch.Tensor(np.load(path, allow_pickle=True))\n",
    "                    matrix = constrain(raw_matrix)\n",
    "                    mats += [matrix[np.argsort(orness(matrix)),:]]\n",
    "        return mats\n",
    "\n",
    "    mats = []\n",
    "    nfeats = []\n",
    "    for f in full_configs:\n",
    "        newmats = get_matrixes(f)\n",
    "        if len(newmats) > 0:\n",
    "            mats += [np.mean(np.stack(newmats, axis=0), axis=0)]\n",
    "            nfeats.append(mats[-1].shape[0])\n",
    "    \n",
    "    filt_configs = configs[1:]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.gca().set_ylim(0, 1)\n",
    "    ax.set_prop_cycle(plt.cycler('color', plt.cm.jet(np.linspace(0, 1, len(mats)))))\n",
    "    plt.xscale(\"log\")\n",
    "    ax.set_xlabel('Feature')\n",
    "    ax.set_ylabel('Orness')\n",
    "        \n",
    "    for i in range(0, len(mats)):\n",
    "        o = orness(mats[i])\n",
    "        if i == 0:\n",
    "            ax.plot([1, 1.001], [o, o])\n",
    "        else:\n",
    "            x = np.arange(o.shape[0]) + 1\n",
    "            ax.plot(x, o)\n",
    "    ax.legend(nfeats, ncol=3, title='$C_{f}$', prop={'size': 6})\n",
    "    \n",
    "    fig.set_size_inches(w=3.5, h=2.5)\n",
    "    plt.tight_layout()\n",
    "    fig.show()\n",
    "    plt.savefig(f'latex_figures/exp_feats_orness.pgf')\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_prop_cycle(plt.cycler('color', plt.cm.jet(np.linspace(0, 1, len(mats)))))\n",
    "    plt.xscale(\"log\")\n",
    "    ax.set_xlabel('Feature')\n",
    "    ax.set_ylabel('Dispersion')\n",
    "        \n",
    "    for i in range(0, len(mats)):\n",
    "        d = dispersion(mats[i])\n",
    "        if i == 0:\n",
    "            ax.plot([1, 1.001], [d, d])\n",
    "        else:\n",
    "            x = np.arange(d.shape[0]) + 1\n",
    "            ax.plot(x, d)\n",
    "    ax.legend(nfeats, ncol=3, title='$C_{f}$', prop={'size': 6}, loc='lower center')\n",
    "    \n",
    "    fig.set_size_inches(w=3.5, h=2.5)\n",
    "    plt.tight_layout()\n",
    "    fig.show()\n",
    "    plt.savefig(f'latex_figures/exp_feats_dispersion.pgf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXP_TAG == 'metrics':\n",
    "    def get_matrixes(config):\n",
    "        if 'constrainmode' in config['config']:\n",
    "            constrain = WeightConstraint(config['config']['constrainmode']).apply\n",
    "        else:\n",
    "            constrain = WeightConstraint('full_owa').apply\n",
    "        mats = []\n",
    "        for it in config['results']:\n",
    "            itid= it['id']\n",
    "            for file in os.listdir(MATRIX_FOLDER):\n",
    "                if file.startswith(itid):\n",
    "                    path = os.path.join(MATRIX_FOLDER, file)\n",
    "                    raw_matrix = torch.Tensor(np.load(path, allow_pickle=True))\n",
    "                    matrix = constrain(raw_matrix)\n",
    "                    mats += [matrix[np.argsort(orness(matrix)),:]]\n",
    "            for file in os.listdir(REF_MATRIX_FOLDER):\n",
    "                if file.startswith(itid):\n",
    "                    path = os.path.join(REF_MATRIX_FOLDER, file)\n",
    "                    raw_matrix = torch.Tensor(np.load(path, allow_pickle=True))\n",
    "                    matrix = constrain(raw_matrix)\n",
    "                    mats += [matrix[np.argsort(orness(matrix)),:]]\n",
    "        return mats\n",
    "\n",
    "    mats = []\n",
    "    for f in full_configs:\n",
    "        newmats = get_matrixes(f)\n",
    "        if len(newmats) > 0:\n",
    "            mats += [np.stack(newmats, axis=0)]\n",
    "\n",
    "    mats = np.stack(mats, axis=0)\n",
    "\n",
    "    meanmats = mats[:, 0, ...]\n",
    "\n",
    "    filt_configs = configs[1:]\n",
    "    \n",
    "    assert len(filt_configs) == meanmats.shape[0]\n",
    "    \n",
    "    fig, ax = plt.subplots(2, 3, sharex=True, sharey=True)\n",
    "    fig.set_size_inches(w=7.1, h=5.1)\n",
    "\n",
    "    fig.text(0.5, 0, 'Sorted input features', ha='center')\n",
    "    fig.text(0, 0.5, 'Output features', va='center', rotation='vertical')\n",
    "    \n",
    "    for i in range(meanmats.shape[0]):\n",
    "        order = convertMetric(filt_configs[i]['order'])\n",
    "        ax.flat[i].set_title(order)\n",
    "        ax.flat[i].imshow(meanmats[i,...], vmin=np.min(meanmats), vmax=np.max(meanmats)*0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.show()\n",
    "    plt.savefig(f'latex_figures/exp_metrics_matrixes.pgf', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXP_TAG == 'metrics':\n",
    "    def get_matrixes(config):\n",
    "        if 'constrainmode' in config['config']:\n",
    "            constrain = WeightConstraint(config['config']['constrainmode']).apply\n",
    "        else:\n",
    "            constrain = WeightConstraint('full_owa').apply\n",
    "        mats = []\n",
    "        for it in config['results']:\n",
    "            itid= it['id']\n",
    "            for file in os.listdir(MATRIX_FOLDER):\n",
    "                if file.startswith(itid):\n",
    "                    path = os.path.join(MATRIX_FOLDER, file)\n",
    "                    raw_matrix = torch.Tensor(np.load(path, allow_pickle=True))\n",
    "                    matrix = constrain(raw_matrix)\n",
    "                    mats += [matrix[np.argsort(orness(matrix)),:]]\n",
    "            for file in os.listdir(REF_MATRIX_FOLDER):\n",
    "                if file.startswith(itid):\n",
    "                    path = os.path.join(REF_MATRIX_FOLDER, file)\n",
    "                    raw_matrix = torch.Tensor(np.load(path, allow_pickle=True))\n",
    "                    matrix = constrain(raw_matrix)\n",
    "                    mats += [matrix[np.argsort(orness(matrix)),:]]\n",
    "        return mats\n",
    "\n",
    "    mats = []\n",
    "    for f in full_configs:\n",
    "        newmats = get_matrixes(f)\n",
    "        if len(newmats) > 0:\n",
    "            mats += [np.stack(newmats, axis=0)]\n",
    "\n",
    "    mats = np.stack(mats, axis=0)\n",
    "    \n",
    "    filt_configs = configs[1:]\n",
    "\n",
    "    meanmats = np.mean(mats, axis=1)\n",
    "    \n",
    "    assert len(filt_configs) == meanmats.shape[0]\n",
    "    \n",
    "    ornessess = np.empty((len(filt_configs), meanmats.shape[1]))\n",
    "    dispersions = np.empty((len(filt_configs), meanmats.shape[1]))\n",
    "    orders = []\n",
    "    for i in range(meanmats.shape[0]):\n",
    "        order = convertMetric(filt_configs[i]['order'])\n",
    "        orders += [order]\n",
    "        ornessess[i, :] = orness(meanmats[i,...])\n",
    "        dispersions[i, :] = dispersion(meanmats[i,...])\n",
    "        \n",
    "    print(ornessess.T.shape)\n",
    "    print(np.argsort(np.mean(ornessess.T, axis=0)).shape)\n",
    "    plotorder = np.argsort(np.mean(ornessess.T, axis=0))[::-1]\n",
    "    print(orders)\n",
    "    print(plotorder)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_prop_cycle(plt.cycler('color', plt.cm.jet(np.linspace(1, 0, len(filt_configs)))))\n",
    "    ax.plot(ornessess.T[:, plotorder])\n",
    "    ax.legend(np.array(orders)[plotorder], prop={'size': 6}, ncol=2)\n",
    "    ax.set_xlabel('Feature')\n",
    "    ax.set_ylabel('Orness')\n",
    "    \n",
    "    fig.set_size_inches(w=3.5, h=2.5)\n",
    "    plt.tight_layout()\n",
    "    fig.show()\n",
    "    plt.savefig(f'latex_figures/exp_metrics_orness.pgf')\n",
    "    \n",
    "    print(plotorder)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_prop_cycle(plt.cycler('color', plt.cm.jet(np.linspace(1, 0, len(filt_configs)))))\n",
    "    ax.plot(dispersions.T[:, plotorder])\n",
    "    ax.legend(np.array(orders)[plotorder], prop={'size': 6}, ncol=2)\n",
    "    ax.set_xlabel('Feature')\n",
    "    ax.set_ylabel('Dispersion')\n",
    "    \n",
    "    fig.set_size_inches(w=3.5, h=2.5)\n",
    "    plt.tight_layout()\n",
    "    fig.show()\n",
    "    plt.savefig(f'latex_figures/exp_metrics_dispersion.pgf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXP_TAG == 'metrics':\n",
    "    def get_matrixes(config):\n",
    "        if 'constrainmode' in config['config']:\n",
    "            constrain = WeightConstraint(config['config']['constrainmode']).apply\n",
    "        else:\n",
    "            constrain = WeightConstraint('full_owa').apply\n",
    "        mats = []\n",
    "        for it in config['results']:\n",
    "            itid= it['id']\n",
    "            for file in os.listdir(MATRIX_FOLDER):\n",
    "                if file.startswith(itid):\n",
    "                    path = os.path.join(MATRIX_FOLDER, file)\n",
    "                    raw_matrix = torch.Tensor(np.load(path, allow_pickle=True))\n",
    "                    matrix = constrain(raw_matrix)\n",
    "                    mats += [matrix[np.argsort(orness(matrix)),:]]\n",
    "            for file in os.listdir(REF_MATRIX_FOLDER):\n",
    "                if file.startswith(itid):\n",
    "                    path = os.path.join(REF_MATRIX_FOLDER, file)\n",
    "                    raw_matrix = torch.Tensor(np.load(path, allow_pickle=True))\n",
    "                    matrix = constrain(raw_matrix)\n",
    "                    mats += [matrix[np.argsort(orness(matrix)),:]]\n",
    "        return mats\n",
    "\n",
    "    mats = []\n",
    "    for f in full_configs:\n",
    "        newmats = get_matrixes(f)\n",
    "        if len(newmats) > 0:\n",
    "            mats += [np.stack(newmats, axis=0)]\n",
    "\n",
    "    mats = np.stack(mats, axis=0)\n",
    "\n",
    "    meanmats = np.mean(mats, axis=1)\n",
    "        \n",
    "    filt_configs = configs[1:]\n",
    "    \n",
    "    assert len(filt_configs) == meanmats.shape[0]\n",
    "    \n",
    "    show = list(range(0,64,16)) + [63]\n",
    "    \n",
    "    fig, ax = plt.subplots(2, 3, sharex=True, sharey=True)\n",
    "    fig.set_size_inches(w=7.1, h=5.1)\n",
    "    \n",
    "    fig.text(0.5, 0, 'Sorted input features (i)', ha='center')\n",
    "    fig.text(0, 0.5, '$w_{i}$', va='center', rotation='vertical')\n",
    "    \n",
    "    for i in range(meanmats.shape[0]):\n",
    "        order = convertMetric(filt_configs[i]['order'])\n",
    "        ax.flat[i].set_title(order)\n",
    "        \n",
    "        legend = list(np.array(show) + 1)\n",
    "        ornesses = orness(meanmats[i, show, :])\n",
    "        for j in range(len(legend)):\n",
    "            legend[j] = f\"{legend[j]} (orness ${ornesses[j]:.2f}$)\"\n",
    "        \n",
    "        ax.flat[i].set_prop_cycle(plt.cycler('color', plt.cm.jet(np.linspace(0, 1, len(show)))))\n",
    "        ax.flat[i].plot(meanmats[i, show, :].T, linewidth=0.8)\n",
    "        ax.flat[i].legend(legend,\n",
    "                          title='Feature',\n",
    "                          prop={'size': 6}, \n",
    "                          ncol=1,\n",
    "                          loc='upper center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.show()\n",
    "    plt.savefig(f'latex_figures/exp_metrics_samples.pgf', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_owa(n, t):\n",
    "    w = np.empty(n)\n",
    "    for i in range(1, n+1):\n",
    "        w[i-1] = scipy.special.comb(n-1,n-i)*np.power(t, n-i)*np.power(1-t, i-1)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sta_owa(n, t, alpha=0.5):\n",
    "    w = np.empty(n)\n",
    "    for i in range(1, n+1):\n",
    "        p1 = np.prod(t + np.arange(0, n-i-1+1)*alpha)\n",
    "        p2 = np.prod(1 - t + np.arange(0, i-2+1)*alpha)\n",
    "        p3 = np.prod(1 + np.arange(0, n-2+1)*alpha)\n",
    "        w[i-1] = scipy.special.comb(n-1,n-i)*p1*p2/p3\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXP_TAG == 'metrics':\n",
    "    def get_matrixes(config):\n",
    "        if 'constrainmode' in config['config']:\n",
    "            constrain = WeightConstraint(config['config']['constrainmode']).apply\n",
    "        else:\n",
    "            constrain = WeightConstraint('full_owa').apply\n",
    "        mats = []\n",
    "        for it in config['results']:\n",
    "            itid= it['id']\n",
    "            for file in os.listdir(MATRIX_FOLDER):\n",
    "                if file.startswith(itid):\n",
    "                    path = os.path.join(MATRIX_FOLDER, file)\n",
    "                    raw_matrix = torch.Tensor(np.load(path, allow_pickle=True))\n",
    "                    matrix = constrain(raw_matrix)\n",
    "                    mats += [matrix[np.argsort(orness(matrix)),:]]\n",
    "            for file in os.listdir(REF_MATRIX_FOLDER):\n",
    "                if file.startswith(itid):\n",
    "                    path = os.path.join(REF_MATRIX_FOLDER, file)\n",
    "                    raw_matrix = torch.Tensor(np.load(path, allow_pickle=True))\n",
    "                    matrix = constrain(raw_matrix)\n",
    "                    mats += [matrix[np.argsort(orness(matrix)),:]]\n",
    "        return mats\n",
    "\n",
    "    mats = []\n",
    "    for f in full_configs:\n",
    "        newmats = get_matrixes(f)\n",
    "        if len(newmats) > 0:\n",
    "            mats += [np.stack(newmats, axis=0)]\n",
    "\n",
    "    mats = np.stack(mats, axis=0)\n",
    "\n",
    "    meanmats = mats[0:1, 0, ...]\n",
    "        \n",
    "    filt_configs = [configs[1]]\n",
    "    \n",
    "    assert len(filt_configs) == meanmats.shape[0]\n",
    "    \n",
    "    show = list(range(0,64,8)) + [63]\n",
    "    show = [0, 4, 11, 14, 53, 63]\n",
    "    \n",
    "    fig, ax = plt.subplots(2, 3, sharex=True, sharey=False)\n",
    "    fig.set_size_inches(w=7.1, h=5.1)\n",
    "    \n",
    "    fig.text(0.5, 0, 'Sorted input features (i)', ha='center')\n",
    "    fig.text(0, 0.5, '$w_{i}$', va='center', rotation='vertical')\n",
    "    \n",
    "    legend = ['Learned operator',\n",
    "             'Binomial OWA',\n",
    "             'Stancu OWA ($\\\\alpha =0.15$)',\n",
    "             'Stancu OWA ($\\\\alpha =0.3$)',\n",
    "             'RIM quantifier (exponential)']\n",
    "    \n",
    "    for i in range(6):\n",
    "        raw_owa = meanmats[0, show[i], :].T\n",
    "        \n",
    "        o = orness(meanmats[0, show[i]:show[i]+1, :])\n",
    "        \n",
    "        w = 5\n",
    "        raw_owa = np.convolve(raw_owa, np.ones(w)/w, 'valid')\n",
    "\n",
    "        ax.flat[i].set_title(f\"Feature {show[i]+1} (orness {o[0]:.2f})\")\n",
    "        \n",
    "        ax.flat[i].plot(raw_owa, linewidth=1)\n",
    "        ax.flat[i].plot(\n",
    "            bin_owa(raw_owa.shape[0], o), \n",
    "            linewidth=0.6)\n",
    "        ax.flat[i].plot(\n",
    "            sta_owa(raw_owa.shape[0], o, alpha = 0.15),\n",
    "            linewidth=0.6)\n",
    "        ax.flat[i].plot(\n",
    "            sta_owa(raw_owa.shape[0], o, alpha = 0.3),\n",
    "            linewidth=0.6)\n",
    "        ax.flat[i].plot(\n",
    "            get_parametric_owa(raw_owa.shape[0], lambda x: rim_generator_for_orness(x, o)),\n",
    "            linewidth=0.6)\n",
    "        \n",
    "        ax.flat[i].legend(legend,\n",
    "                          prop={'size': 6}, \n",
    "                          ncol=1,\n",
    "                          loc='upper center')\n",
    "    \n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    fig.show()\n",
    "    plt.savefig(f'latex_figures/exp_metrics_samples.pgf', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OWA_Layer",
   "language": "python",
   "name": "owa_layer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
